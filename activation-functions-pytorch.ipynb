{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"! pip install --quiet \"matplotlib\" \"torchvision\" \"torchmetrics>=0.7, <0.12\" \"setuptools==67.4.0\" \"seaborn\" \"lightning>=2.0.0rc0\" \"pytorch-lightning>=1.4, <2.0.0\" \"torch>=1.8.1, <1.14.0\" \"ipython[notebook]>=8.0.0, <8.12.0\"","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-09-12T07:10:12.455216Z","iopub.execute_input":"2023-09-12T07:10:12.455579Z","iopub.status.idle":"2023-09-12T07:12:21.055339Z","shell.execute_reply.started":"2023-09-12T07:10:12.455529Z","shell.execute_reply":"2023-09-12T07:12:21.053965Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Activation Function\n* Decides whether a neuron should be activated or not. This means it will decide whether the neuron's input to the network is important or not in the process of prediction using simpler mathematical operations\n* They also add non-linearity to the neural network - gives the neural network the ability to solve complex problems (understanding complex relationships or patterns between different features)\n* How does it work???\n    * inputs are fed into the network from the input layer. In the neurons of the next layer, a weighted sum of the inputs is calculated and a bias is added to the sum. This sum is then passed through an activation function and the output of this activation function is the input of the next layer","metadata":{}},{"cell_type":"code","source":"import json\nimport math\nimport os\nimport urllib.request\nimport warnings\nfrom urllib.error import HTTPError\n\nimport matplotlib.pyplot as plt\n\n%matplotlib inline\nimport matplotlib_inline.backend_inline\nimport numpy as np\nimport seaborn as sns\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nimport torch.utils.data as data\nimport torchvision\nfrom torchvision import transforms\nfrom torchvision.datasets import FashionMNIST\nfrom tqdm.notebook import tqdm\nmatplotlib_inline.backend_inline.set_matplotlib_formats(\"svg\", \"pdf\")  # For export\nsns.set()\n","metadata":{"execution":{"iopub.status.busy":"2023-09-12T07:56:55.123347Z","iopub.execute_input":"2023-09-12T07:56:55.123724Z","iopub.status.idle":"2023-09-12T07:56:55.136337Z","shell.execute_reply.started":"2023-09-12T07:56:55.123693Z","shell.execute_reply":"2023-09-12T07:56:55.135382Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Reproducibility","metadata":{}},{"cell_type":"code","source":"# Path to the folder where the datasets are/should be downloaded (e.g. MNIST)\nDATASET_PATH = os.environ.get(\"PATH_DATASETS\", \"data/\")\n# Path to the folder where the pretrained models are saved\nCHECKPOINT_PATH = os.environ.get(\"PATH_CHECKPOINT\", \"saved_models/Activation_Functions/\")\n\n\n# Function for setting the seed\ndef set_seed(seed):\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    if torch.cuda.is_available():  # GPU operation have separate seed\n        torch.cuda.manual_seed(seed)\n        torch.cuda.manual_seed_all(seed)\n\n\nset_seed(42)\n\n# Additionally, some operations on a GPU are implemented stochastic for efficiency\n# We want to ensure that all operations are deterministic on GPU (if used) for reproducibility\ntorch.backends.cudnn.deterministic = True\ntorch.backends.cudnn.benchmark = False\n\n# Fetching the device that will be used throughout this notebook\ndevice = torch.device(\"cpu\") if not torch.cuda.is_available() else torch.device(\"cuda:0\")\nprint(\"Using device\", device)","metadata":{"execution":{"iopub.status.busy":"2023-09-12T07:12:24.168856Z","iopub.execute_input":"2023-09-12T07:12:24.169584Z","iopub.status.idle":"2023-09-12T07:12:24.240084Z","shell.execute_reply.started":"2023-09-12T07:12:24.169532Z","shell.execute_reply":"2023-09-12T07:12:24.239037Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Github URL where saved models are stored for this tutorial\nbase_url = \"https://raw.githubusercontent.com/phlippe/saved_models/main/tutorial3/\"\n# Files to download\npretrained_files = [\n    \"FashionMNIST_elu.config\",\n    \"FashionMNIST_elu.tar\",\n    \"FashionMNIST_leakyrelu.config\",\n    \"FashionMNIST_leakyrelu.tar\",\n    \"FashionMNIST_relu.config\",\n    \"FashionMNIST_relu.tar\",\n    \"FashionMNIST_sigmoid.config\",\n    \"FashionMNIST_sigmoid.tar\",\n    \"FashionMNIST_swish.config\",\n    \"FashionMNIST_swish.tar\",\n    \"FashionMNIST_tanh.config\",\n    \"FashionMNIST_tanh.tar\",\n]\n\nos.makedirs(CHECKPOINT_PATH, exist_ok = True)\nfor file_name in pretrained_files:\n    file_path = os.path.join(CHECKPOINT_PATH,file_name)\n    if not os.path.isfile(file_path):\n        file_url = base_url + file_name\n        print(f\"Downloading {file_url}..\")\n        try:\n            urllib.request.urlretrieve(file_url, file_path)\n        except HTTPError as e:\n            print(\n                \"Something went wrong. Please try to download the file from the GDrive folder, or contact the author with the full output including the following error:\\n\",\n                e,\n            )\n            ","metadata":{"execution":{"iopub.status.busy":"2023-09-12T07:13:19.328302Z","iopub.execute_input":"2023-09-12T07:13:19.328699Z","iopub.status.idle":"2023-09-12T07:13:23.129612Z","shell.execute_reply.started":"2023-09-12T07:13:19.328669Z","shell.execute_reply":"2023-09-12T07:13:23.128231Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Original Optimization Functions\n* Sigmoid:\n    * suffers from the vanishing gradient problem which results in the network refusing to learn further or being too slow to reach an accurate prediction\n    * Outputs are not zero centered\n    * Fails deep neural networks as the highest gradient it provides is 0.25 leading to vanishing gradients in early layers\n* Tanh \n    * suffers from the vanishing gradient problem too but the derivatives are steeper than that of the sigmoid\n    ","metadata":{}},{"cell_type":"code","source":"#base class which all our future modules will inherit\nclass ActivationFunction(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.name = self.__class__.__name__\n        self.config = {\"name\": self.name}\n#available as a pytorch function torch.sigmoid or a nn module nn.Sigmoid\nclass Sigmoid(ActivationFunction):\n    def forward(self, x):\n        return 1/(1+torch.exp(-x))\n\n#available as a pytorch function torch.tanh or a nn module nn.Tanh\nclass Tanh(ActivationFunction):\n    def forward(self, x):\n        x_exp, neg_x_exp = torch.exp(x), torch.exp(-x)\n        return (x_exp-neg_x_exp)/ (x_exp + neg_x_exp)\n    \n\n        ","metadata":{"execution":{"iopub.status.busy":"2023-09-12T07:57:08.631654Z","iopub.execute_input":"2023-09-12T07:57:08.632003Z","iopub.status.idle":"2023-09-12T07:57:08.639626Z","shell.execute_reply.started":"2023-09-12T07:57:08.631974Z","shell.execute_reply":"2023-09-12T07:57:08.638616Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Relu\n* Relu - Rectified Linear Unit: advantage is has a strong, stable gradient for a large range of values hence allowing training of deeper networks\n* variants include:\n    * LeakyReLU - replaces the zero settings in the negative part with a smaller slope to allow gradients to flow also in this part of the input\n    * ELU - replaces the negative part with an exponential decay\n    * Swish - both smooth and monotonic(contains a change of sign in the gradient). This prevents dead neurons as in standard ReLU activation\n    \n    ","metadata":{}},{"cell_type":"code","source":"class ReLU(ActivationFunction):\n    def forward(self, x):\n        return x * (x>0).float()\n    \nclass LeakyReLU(ActivationFunction):\n    def __init__(self, alpha = 0.1):\n        super().__init__()\n        self.config['alpha'] = alpha\n        \n    def forward(self, x):\n        return torch.where(x>0, x, self.config[\"alpha\"] * x)\n    \nclass ELU(ActivationFunction):\n    def forward(self, x):\n        return torch.where(x>0, x, torch.exp(x)-1)\n    \nclass Swish(ActivationFunction):\n    def forward(self, x):\n        return x * torch.sigmoid(x)\n    \n","metadata":{"execution":{"iopub.status.busy":"2023-09-12T07:57:10.067521Z","iopub.execute_input":"2023-09-12T07:57:10.067915Z","iopub.status.idle":"2023-09-12T07:57:10.075427Z","shell.execute_reply.started":"2023-09-12T07:57:10.067885Z","shell.execute_reply":"2023-09-12T07:57:10.074560Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Visualizing them","metadata":{}},{"cell_type":"code","source":"act_fn_by_name = {\"sigmoid\": Sigmoid, \"tanh\": Tanh, \"relu\": ReLU, \"leakyrelu\": LeakyReLU, \"elu\": ELU, \"swish\": Swish}\ndef get_grads(act_fn, x):\n    x = x.clone().requires_grad_() #mark the input as a tensor for which we want to store gradients\n    out = act_fn(x)\n    out.sum().backward() #sum results in an equal gradient flow to each element in x\n    return x.grad #access the gradients of x by \"x.grad\"\n\ndef vis_act_fn(act_fn, ax, x):\n    # Run activation function\n    y = act_fn(x)\n    y_grads = get_grads(act_fn, x)\n    # Push x, y and gradients back to cpu for plotting\n    x, y, y_grads = x.cpu().numpy(), y.cpu().numpy(), y_grads.cpu().numpy()\n    # Plotting\n    ax.plot(x, y, linewidth=2, label=\"ActFn\")\n    ax.plot(x, y_grads, linewidth=2, label=\"Gradient\")\n    ax.set_title(act_fn.name)\n    ax.legend()\n    ax.set_ylim(-1.5, x.max())\n\n\n# Add activation functions if wanted\nact_fns = [act_fn() for act_fn in act_fn_by_name.values()]\nx = torch.linspace(-5, 5, 1000)  # Range on which we want to visualize the activation functions\n# Plotting\ncols = 2\nrows = math.ceil(len(act_fns) / float(cols))\nfig, ax = plt.subplots(rows, cols, figsize=(cols * 4, rows * 4))\nfor i, act_fn in enumerate(act_fns):\n    vis_act_fn(act_fn, ax[divmod(i, cols)], x)\nfig.subplots_adjust(hspace=0.3)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-09-12T07:57:12.059361Z","iopub.execute_input":"2023-09-12T07:57:12.060442Z","iopub.status.idle":"2023-09-12T07:57:15.699664Z","shell.execute_reply.started":"2023-09-12T07:57:12.060398Z","shell.execute_reply":"2023-09-12T07:57:15.698469Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Gaining insights into each optimization effects\n#### Setup","metadata":{}},{"cell_type":"code","source":"class BaseNetwork(nn.Module):\n    def __init__(self, act_fn, input_size = 784, num_classes = 10, hidden_sizes = [512,256,256, 128]):\n        \"\"\"\n            Args:\n                act_fn: object of the activation fn that should be used in non linearity in the network\n                input_size: Size of the input images in pixels\n                num_classes: number of classes we want to predict\n                hidden sizes: A list of integers specifying the hidden layer sizes in the NN\n        \"\"\"\n        super().__init__()\n        \n        layers = []\n        layer_sizes = [input_size] + hidden_sizes\n        layer_size_last = layer_sizes[0]\n        for layer_size in layer_sizes[1:]:\n            layers += [nn.Linear(layer_size_last, layer_size), act_fn]\n            layer_size_last = layer_size\n            \n        layers += [nn.Linear(layer_sizes[-1], num_classes)]\n        #nn.Sequential summarizes a list of modules into a single module, applying them in sequence\n        self.layers = nn.Sequential(*layers)\n        \n        self.config = {\n            \"act_fn\": act_fn.config,\n            \"input_size\": input_size,\n            \"num_classes\": num_classes,\n            \"hidden_sizes\": hidden_sizes,\n        }\n        \n    def forward(self, x):\n        x = x.view(x.size(0), -1) #reshape images to a flat vector\n        out = self.layers(x)\n        return out","metadata":{"execution":{"iopub.status.busy":"2023-09-12T08:13:49.392660Z","iopub.execute_input":"2023-09-12T08:13:49.394066Z","iopub.status.idle":"2023-09-12T08:13:49.403777Z","shell.execute_reply.started":"2023-09-12T08:13:49.393995Z","shell.execute_reply":"2023-09-12T08:13:49.402476Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def _get_config_file(model_path, model_name):\n    return os.path.join(model_path, model_name + \".config\")\n\ndef _get_model_file(model_path, model_name):\n    return os.path.join(model_path, model_name + \".tar\")\n\ndef load_model(model_path, model_name, net=None):\n    config_file, model_file = _get_config_file(model_path, model_name), _get_model_file(model_path, model_name)\n    assert os.path.isfile(\n        config_file\n    ), f'Could not find the config file \"{config_file}\". Are you sure this is the correct path and you have your model config stored here?'\n    assert os.path.isfile(\n        model_file\n    ), f'Could not find the model file \"{model_file}\". Are you sure this is the correct path and you have your model stored here?'    \n    \n    with open(config_file) as f:\n        config_dict = json.load(f)\n    if net is None:\n        act_fn_name = config_dict[\"act_fn\"].pop(\"name\").lower()\n        act_fn = act_fn_by_name[act_fn_name](**config_dict.pop(\"act_fn\"))\n        net = BaseNetwork(act_fn=act_fn, **config_dict)\n    net.load_state_dict(torch.load(model_file, map_location=device))\n    return net\n\ndef save_model(model, model_path, model_name):\n    config_dict = model.config\n    os.makedirs(model_path, exist_ok=True)\n    config_file, model_file = _get_config_file(model_path, model_name), _get_model_file(model_path, model_name)\n    with open(config_file, \"w\") as f:\n        json.dump(config_dict, f)\n    torch.save(model.state_dict(), model_file)    \n    \n    ","metadata":{"execution":{"iopub.status.busy":"2023-09-12T08:19:25.277877Z","iopub.execute_input":"2023-09-12T08:19:25.278227Z","iopub.status.idle":"2023-09-12T08:19:25.288865Z","shell.execute_reply.started":"2023-09-12T08:19:25.278198Z","shell.execute_reply":"2023-09-12T08:19:25.287736Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Datasets and Transforms","metadata":{}},{"cell_type":"code","source":"\n# Transformations applied on each image => first make them a tensor, then normalize them in the range -1 to 1\ntransform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n\n# Loading the training dataset. We need to split it into a training and validation part\ntrain_dataset = FashionMNIST(root=DATASET_PATH, train=True, transform=transform, download=True)\ntrain_set, val_set = torch.utils.data.random_split(train_dataset, [50000, 10000])\n\n# Loading the test set\ntest_set = FashionMNIST(root=DATASET_PATH, train=False, transform=transform, download=True)","metadata":{"execution":{"iopub.status.busy":"2023-09-12T08:22:40.850956Z","iopub.execute_input":"2023-09-12T08:22:40.851328Z","iopub.status.idle":"2023-09-12T08:22:47.364893Z","shell.execute_reply.started":"2023-09-12T08:22:40.851297Z","shell.execute_reply":"2023-09-12T08:22:47.363876Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Data Loader","metadata":{}},{"cell_type":"code","source":"train_loader = data.DataLoader(train_set, batch_size=1024, shuffle=True, drop_last=False)\nval_loader = data.DataLoader(val_set, batch_size=1024, shuffle=False, drop_last=False)\ntest_loader = data.DataLoader(test_set, batch_size=1024, shuffle=False, drop_last=False)","metadata":{"execution":{"iopub.status.busy":"2023-09-12T08:23:12.494641Z","iopub.execute_input":"2023-09-12T08:23:12.495007Z","iopub.status.idle":"2023-09-12T08:23:12.501340Z","shell.execute_reply.started":"2023-09-12T08:23:12.494978Z","shell.execute_reply":"2023-09-12T08:23:12.500400Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"exmp_imgs = [train_set[i][0] for i in range(16)]\n# Organize the images into a grid for nicer visualization\nimg_grid = torchvision.utils.make_grid(torch.stack(exmp_imgs, dim=0), nrow=4, normalize=True, pad_value=0.5)\nprint(img_grid.shape)\nimg_grid = img_grid.permute(1, 2, 0)\n\nplt.figure(figsize=(8, 8))\nplt.title(\"FashionMNIST examples\")\nplt.imshow(img_grid)\nplt.axis(\"off\")\nplt.show()\nplt.close()","metadata":{"execution":{"iopub.status.busy":"2023-09-12T08:24:17.875883Z","iopub.execute_input":"2023-09-12T08:24:17.876240Z","iopub.status.idle":"2023-09-12T08:24:18.505484Z","shell.execute_reply.started":"2023-09-12T08:24:17.876211Z","shell.execute_reply":"2023-09-12T08:24:18.504253Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Visualizing the gradient flow after Inititialization\n* if the gradient through the activation function is in expectation(considerably smaller than 1) then we will vanish until they reach the input layer. If the gradient through the activation function is larger than 1, the gradients exponetially increase and might explode","metadata":{}},{"cell_type":"code","source":"def visualize_gradients(net, color=\"C0\"):\n    \"\"\"\n    Args:\n        net: Object of class BaseNetwork\n        color: Color in which we want to visualize the histogram (for easier separation of activation functions)\n    \"\"\"\n    net.eval()\n    small_loader = data.DataLoader(train_set, batch_size=256, shuffle=False)\n    imgs, labels = next(iter(small_loader))\n    imgs, labels = imgs.to(device), labels.to(device)\n\n    # Pass one batch through the network, and calculate the gradients for the weights\n    net.zero_grad()\n    preds = net(imgs)\n    loss = F.cross_entropy(preds, labels)\n    loss.backward()\n    # We limit our visualization to the weight parameters and exclude the bias to reduce the number of plots\n    grads = {\n        name: params.grad.data.view(-1).cpu().clone().numpy()\n        for name, params in net.named_parameters()\n        if \"weight\" in name\n    }\n    net.zero_grad()\n\n    # Plotting\n    columns = len(grads)\n    fig, ax = plt.subplots(1, columns, figsize=(columns * 3.5, 2.5))\n    fig_index = 0\n    for key in grads:\n        key_ax = ax[fig_index % columns]\n        sns.histplot(data=grads[key], bins=30, ax=key_ax, color=color, kde=True)\n        key_ax.set_title(str(key))\n        key_ax.set_xlabel(\"Grad magnitude\")\n        fig_index += 1\n    fig.suptitle(\n        f\"Gradient magnitude distribution for activation function {net.config['act_fn']['name']}\", fontsize=14, y=1.05\n    )\n    fig.subplots_adjust(wspace=0.45)\n    plt.show()\n    plt.close()","metadata":{"execution":{"iopub.status.busy":"2023-09-12T08:31:24.151537Z","iopub.execute_input":"2023-09-12T08:31:24.152604Z","iopub.status.idle":"2023-09-12T08:31:24.164169Z","shell.execute_reply.started":"2023-09-12T08:31:24.152533Z","shell.execute_reply":"2023-09-12T08:31:24.163005Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Seaborn prints warnings if histogram has small values. We can ignore them for now\nwarnings.filterwarnings(\"ignore\")\n# Create a plot for every activation function\nfor i, act_fn_name in enumerate(act_fn_by_name):\n    # Setting the seed ensures that we have the same weight initialization for each activation function\n    set_seed(42)\n    act_fn = act_fn_by_name[act_fn_name]()\n    net_actfn = BaseNetwork(act_fn=act_fn).to(device)\n    visualize_gradients(net_actfn, color=f\"C{i}\")","metadata":{"execution":{"iopub.status.busy":"2023-09-12T08:31:35.989180Z","iopub.execute_input":"2023-09-12T08:31:35.989553Z","iopub.status.idle":"2023-09-12T08:32:17.515810Z","shell.execute_reply.started":"2023-09-12T08:31:35.989511Z","shell.execute_reply":"2023-09-12T08:32:17.514716Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* All the other activation functions show to have similar gradient norms across all layers except for sigmoid  where the input layer has the lowest gradient norm(1e-05) \n* ReLU has a spike around 0 which is caused by its zero-part on the left and dead neurons\n","metadata":{}},{"cell_type":"markdown","source":"### Train the Model","metadata":{}},{"cell_type":"code","source":"def train_model(net, model_name, max_epochs = 50, patience = 7, batch_size =256, overwrite= False):\n    file_exists = os.path.isfile(_get_model_file(CHECKPOINT_PATH, model_name))\n    if file_exists and not overwrite:\n        print(\"Model file already exists. Skipping training...\")\n    else:\n        if file_exists:\n            print(\"Model file exists, but will be overwritten...\")\n            \n        optimizer = optim.SGD(net.parameters(), lr = 1e-02, momentum = 0.9)\n        loss_module = nn.CrossEntropyLoss()\n        train_loader_local = data.DataLoader(train_set, batch_size=batch_size, shuffle=True, drop_last=True, pin_memory=True)\n        val_scores = []\n        best_val_epoch = -1\n        for epoch in range(max_epochs):\n            net.train()\n            true_preds , count = 0 , 0\n            for imgs, labels in tqdm(train_loader_local, desc=f\"Epoch {epoch+1}\", leave=False):\n                imgs, labels = imgs.to(device), labels.to(device)\n                optimizer.zero_grad()\n                preds = net(imgs)\n                loss = loss_module(preds, labels)\n                loss.backward()\n                optimizer.step()\n                true_preds += (preds.argmax(dim=-1)==labels).sum()\n                count += labels.shape[0]\n            train_acc = true_preds/count\n            \n            val_acc = test_model(net, val_loader)\n            val_scores.append(val_acc)\n            print(\n                f\"[Epoch {epoch+1:2i}] Training accuracy: {train_acc*100.0:05.2f}%, Validation accuracy: {val_acc*100.0:05.2f}%\"\n            )\n\n            if len(val_scores) == 1 or val_acc > val_scores[best_val_epoch]:\n                print(\"\\t   (New best performance, saving model...)\")\n                save_model(net, CHECKPOINT_PATH, model_name)\n                best_val_epoch = epoch\n            elif best_val_epoch <= epoch - patience:\n                print(f\"Early stopping due to no improvement over the last {patience} epochs\")\n                break\n\n        # Plot a curve of the validation accuracy\n        plt.plot([i for i in range(1, len(val_scores) + 1)], val_scores)\n        plt.xlabel(\"Epochs\")\n        plt.ylabel(\"Validation accuracy\")\n        plt.title(f\"Validation performance of {model_name}\")\n        plt.show()\n        plt.close() \n        \n    load_model(CHECKPOINT_PATH, model_name, net=net)\n    test_acc = test_model(net, test_loader)\n    print((f\" Test accuracy: {test_acc*100.0:4.2f}% \").center(50, \"=\") + \"\\n\")\n    return test_acc\n \ndef test_model(net, data_loader):\n    \"\"\"Test a model on a specified dataset.\n\n    Args:\n        net: Trained model of type BaseNetwork\n        data_loader: DataLoader object of the dataset to test on (validation or test)\n    \"\"\"\n    net.eval()\n    true_preds, count = 0.0, 0\n    for imgs, labels in data_loader:\n        imgs, labels = imgs.to(device), labels.to(device)\n        with torch.no_grad():\n            preds = net(imgs).argmax(dim=-1)\n            true_preds += (preds == labels).sum().item()\n            count += labels.shape[0]\n    test_acc = true_preds / count\n    return test_acc\n            ","metadata":{"execution":{"iopub.status.busy":"2023-09-12T08:49:39.621808Z","iopub.execute_input":"2023-09-12T08:49:39.622283Z","iopub.status.idle":"2023-09-12T08:49:39.639449Z","shell.execute_reply.started":"2023-09-12T08:49:39.622246Z","shell.execute_reply":"2023-09-12T08:49:39.638532Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for act_fn_name in act_fn_by_name:\n    print(f\"Training BaseNetwork with {act_fn_name} activation...\")\n    set_seed(42)\n    act_fn = act_fn_by_name[act_fn_name]()\n    net_actfn = BaseNetwork(act_fn=act_fn).to(device)\n    train_model(net_actfn, f\"FashionMNIST_{act_fn_name}\", overwrite=False)","metadata":{"execution":{"iopub.status.busy":"2023-09-12T08:49:39.771774Z","iopub.execute_input":"2023-09-12T08:49:39.772311Z","iopub.status.idle":"2023-09-12T08:49:50.526924Z","shell.execute_reply.started":"2023-09-12T08:49:39.772275Z","shell.execute_reply":"2023-09-12T08:49:50.525160Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Visualizing the Activation Function","metadata":{}},{"cell_type":"code","source":"def visualize_activations(net, color=\"C0\"):\n    activations = {}\n\n    net.eval()\n    small_loader = data.DataLoader(train_set, batch_size=1024)\n    imgs, labels = next(iter(small_loader))\n    with torch.no_grad():\n        layer_index = 0\n        imgs = imgs.to(device)\n        imgs = imgs.view(imgs.size(0), -1)\n        # We need to manually loop through the layers to save all activations\n        for layer_index, layer in enumerate(net.layers[:-1]):\n            imgs = layer(imgs)\n            activations[layer_index] = imgs.view(-1).cpu().numpy()\n\n    # Plotting\n    columns = 4\n    rows = math.ceil(len(activations) / columns)\n    fig, ax = plt.subplots(rows, columns, figsize=(columns * 2.7, rows * 2.5))\n    fig_index = 0\n    for key in activations:\n        key_ax = ax[fig_index // columns][fig_index % columns]\n        sns.histplot(data=activations[key], bins=50, ax=key_ax, color=color, kde=True, stat=\"density\")\n        key_ax.set_title(f\"Layer {key} - {net.layers[key].__class__.__name__}\")\n        fig_index += 1\n    fig.suptitle(f\"Activation distribution for activation function {net.config['act_fn']['name']}\", fontsize=14)\n    fig.subplots_adjust(hspace=0.4, wspace=0.4)\n    plt.show()\n    plt.close()\n","metadata":{"execution":{"iopub.status.busy":"2023-09-12T08:59:40.315332Z","iopub.execute_input":"2023-09-12T08:59:40.315732Z","iopub.status.idle":"2023-09-12T08:59:40.325871Z","shell.execute_reply.started":"2023-09-12T08:59:40.315702Z","shell.execute_reply":"2023-09-12T08:59:40.324897Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i, act_fn_name in enumerate(act_fn_by_name):\n    net_actfn = load_model(model_path=CHECKPOINT_PATH, model_name=f\"FashionMNIST_{act_fn_name}\").to(device)\n    visualize_activations(net_actfn, color=f\"C{i}\")","metadata":{"execution":{"iopub.status.busy":"2023-09-12T08:59:53.006800Z","iopub.execute_input":"2023-09-12T08:59:53.007158Z","iopub.status.idle":"2023-09-12T09:01:26.615651Z","shell.execute_reply.started":"2023-09-12T08:59:53.007130Z","shell.execute_reply":"2023-09-12T09:01:26.614794Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Different activation functions show diverse behaviors and it is apparent that the selction of the \"optimal\" activation function really depends on many factors and is not the same for all possible networks","metadata":{}},{"cell_type":"markdown","source":"### Findind Dead Neurons in ReLU networks\n* Dead neurons means neurons with no gradients for any training input. The issue of dead neurons is that as no gradient is provided for the layer, we cannot train the parameters of this neuron in the previous layer to obtain output values besides zero\n* For dead neurons to occur the output value of the linear layer before the ReLU has to be negative for all input images","metadata":{}},{"cell_type":"code","source":"@torch.no_grad()\ndef measure_number_dead_neurons(net):\n    \"\"\"Function to measure the number of dead neurons in a trained neural network.\n\n    For each neuron, we create a boolean variable initially set to 1. If it has an activation unequals 0 at any time, we\n    set this variable to 0. After running through the whole training set, only dead neurons will have a 1.\n    \"\"\"\n    neurons_dead = [\n        torch.ones(layer.weight.shape[0], device=device, dtype=torch.bool)\n        for layer in net.layers[:-1]\n        if isinstance(layer, nn.Linear)\n    ]  # Same shapes as hidden size in BaseNetwork\n\n    net.eval()\n    for imgs, labels in tqdm(train_loader, leave=False):  # Run through whole training set\n        layer_index = 0\n        imgs = imgs.to(device)\n        imgs = imgs.view(imgs.size(0), -1)\n        for layer in net.layers[:-1]:\n            imgs = layer(imgs)\n            if isinstance(layer, ActivationFunction):\n                # Are all activations == 0 in the batch, and we did not record the opposite in the last batches?\n                neurons_dead[layer_index] = torch.logical_and(neurons_dead[layer_index], (imgs == 0).all(dim=0))\n                layer_index += 1\n    number_neurons_dead = [t.sum().item() for t in neurons_dead]\n    print(\"Number of dead neurons:\", number_neurons_dead)\n    print(\n        \"In percentage:\",\n        \", \".join(\n            [f\"{(100.0 * num_dead / tens.shape[0]):4.2f}%\" for tens, num_dead in zip(neurons_dead, number_neurons_dead)]\n        ),\n    )\n    \nset_seed(42)\nnet_relu = BaseNetwork(act_fn=ReLU()).to(device)\nmeasure_number_dead_neurons(net_relu)    ","metadata":{"execution":{"iopub.status.busy":"2023-09-12T09:10:40.486165Z","iopub.execute_input":"2023-09-12T09:10:40.486557Z","iopub.status.idle":"2023-09-12T09:10:49.671444Z","shell.execute_reply.started":"2023-09-12T09:10:40.486514Z","shell.execute_reply":"2023-09-12T09:10:49.670516Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* Only a minor amount of neurons as dead but they increase with the depth of the layer. However, this is not a problem for the small number of dead neurons we have as the input to later layers is changed due to updates to the weights of previous layers. Therefore dead neurons in later layers can potentially become alive/active again as seen below\n* The only problem is when we have dead neurons in the input layer as this dont chhange over epochs","metadata":{}},{"cell_type":"code","source":"#how does this look for a trained network\nnet_relu = load_model(model_path=CHECKPOINT_PATH, model_name=\"FashionMNIST_relu\").to(device)\nmeasure_number_dead_neurons(net_relu)","metadata":{"execution":{"iopub.status.busy":"2023-09-12T09:11:40.993785Z","iopub.execute_input":"2023-09-12T09:11:40.994155Z","iopub.status.idle":"2023-09-12T09:11:50.282111Z","shell.execute_reply.started":"2023-09-12T09:11:40.994128Z","shell.execute_reply":"2023-09-12T09:11:50.281057Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#how do they increase with an increaase in layer depth?\nset_seed(42)\nnet_relu = BaseNetwork(\n    act_fn=ReLU(),\n    hidden_sizes=[256, 256, 256, 256, 256, 128, 128, 128, 128, 128],\n).to(device)\nmeasure_number_dead_neurons(net_relu)\n","metadata":{"execution":{"iopub.status.busy":"2023-09-12T09:21:16.595093Z","iopub.execute_input":"2023-09-12T09:21:16.595468Z","iopub.status.idle":"2023-09-12T09:21:26.527777Z","shell.execute_reply.started":"2023-09-12T09:21:16.595436Z","shell.execute_reply":"2023-09-12T09:21:26.526825Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* The number of dead neurons is significantly higher than before which harms the gradient flow especially in the first iterations. \n* Hence it is advisable to use other nonlinearities like Swish for very deep networks","metadata":{}},{"cell_type":"markdown","source":"### Conclusion\n* It is advisable to start with a ReLU- based network as all the ReLU variants tend to perform better and select the specific activation function based on the properties of the network\n* Sigmoid failes deep neural networks as the highest gradients it provides is 0.25 leading to vanishing gradients in early layers.","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}],"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}}