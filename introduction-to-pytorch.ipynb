{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/stephenkolesh/introduction-to-pytorch?scriptVersionId=142643817\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"code","source":"import time\n\nimport matplotlib.pyplot as plt\n\n%matplotlib inline\nimport matplotlib_inline.backend_inline\nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport torch.utils.data as data\nfrom matplotlib.colors import to_rgba\nfrom torch import Tensor\nfrom tqdm.notebook import tqdm  # Progress bar\n\nmatplotlib_inline.backend_inline.set_matplotlib_formats(\"svg\", \"pdf\")  # For export","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-09-11T12:39:06.434821Z","iopub.execute_input":"2023-09-11T12:39:06.435196Z","iopub.status.idle":"2023-09-11T12:39:07.954858Z","shell.execute_reply.started":"2023-09-11T12:39:06.435164Z","shell.execute_reply":"2023-09-11T12:39:07.953844Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Using torch\", torch.__version__)","metadata":{"execution":{"iopub.status.busy":"2023-09-11T12:39:07.956875Z","iopub.execute_input":"2023-09-11T12:39:07.957431Z","iopub.status.idle":"2023-09-11T12:39:07.963939Z","shell.execute_reply.started":"2023-09-11T12:39:07.957398Z","shell.execute_reply":"2023-09-11T12:39:07.963019Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"torch.manual_seed(42) #reproducibility","metadata":{"execution":{"iopub.status.busy":"2023-09-11T12:39:07.965274Z","iopub.execute_input":"2023-09-11T12:39:07.966233Z","iopub.status.idle":"2023-09-11T12:39:07.979725Z","shell.execute_reply.started":"2023-09-11T12:39:07.966201Z","shell.execute_reply":"2023-09-11T12:39:07.978638Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Tensors\n* A vector is a 1-D tensor, a matric is a 2-D tensor, etc\n* Tensor Creation\n    * torch.zeros  creates a tensor filled with zeros\n    * torch.ones creates a tensor filled with ones\n    * torch.rand creates a tensor with random values uniformly sampled between o and 1\n    * torch.randn creates a tensor with random values sampled from a normal distribution with mean 0 and variance 1\n    * torch.arange creates a tensor containing the values N, N+1, N+2, ...., M\n    * torc.Tensor(input list) creates a tensor from the list you provide\n* Tensor Shape and Size\n    * x.shape\n    * x.size()\n    \n* Tensor to Numpy and Numpy to Tensor\n    * Numpy to tensor: torch.from_numpy()\n    * Tensor to Numpy: x.numpy() -> this requires the tensor to be on the CPU and not the GPU, call .cpu() on the tensor before hand \n        * np_arr = tensor.cpu().numpy()\n        \n* Tensor reshaping\n    * View -> a tensor of 2,3 can be reshaped to any other shape with the same number of elements (e.g a tensor of size(6), or (3,2) ..\n    * permute: swap dimensions(0,1)\n    \n* Tensor Operations\n    * addition: x+ y or x.add_(y)\n    * torch.matmul : performs matrix product over two tensors, where the specific behavior depends on the dimensions. If both inputs are matrices (2-dimensional tensors) it performs the standard matrix product. For higher dimensional inputs, the function supports broad casting\n    * torch.mm : performs matrix product over two matrices but doesnt support broadcasting\n    * torch.bmm : performs matrix product with a support batch dimension\n    * torch.einsum : perfroms matrix multiplications and more (sums of products) using the einstein summation convention\n    \n    * mostly used are: torch.matmul and torch.bmm\n    ","metadata":{}},{"cell_type":"code","source":"x = Tensor(2, 3 , 4) #creates a tensor from the given list\nprint(x)\nprint(\"shape\",x.shape)\nprint(\"size\", x.size())\nprint(\"-\" * 35)\nx = Tensor([[2,3], [4,5]]) #creates a tesnor from e nested list\nprint(x)\nprint(\"shape\",x.shape)\nprint(\"size\", x.size())\nprint(\"-\" * 35)\nx = torch.rand(2,3,4) #creates a tensor with random values between 0 and 1 with the shape [2,3,4]\nprint(x)\nprint(\"shape\",x.shape)\nprint(\"size\", x.size())\nprint(\"-\" * 35)","metadata":{"execution":{"iopub.status.busy":"2023-09-11T12:39:07.982596Z","iopub.execute_input":"2023-09-11T12:39:07.983153Z","iopub.status.idle":"2023-09-11T12:39:08.068203Z","shell.execute_reply.started":"2023-09-11T12:39:07.983121Z","shell.execute_reply":"2023-09-11T12:39:08.067291Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"np_array = np.array([[1,2], [3,4]])\ntensor = torch.from_numpy(np_array)\nprint(\"np_array\", np_array)\nprint(\"tensor\", tensor)\nprint(\"-\" * 50)\n\ntensor = torch.ones(3)\nnp_array = tensor.numpy()\n\nprint(\"tensor\", tensor)\nprint(\"np_array\", np_array)\nprint(\"-\" * 50)","metadata":{"execution":{"iopub.status.busy":"2023-09-11T12:39:08.069543Z","iopub.execute_input":"2023-09-11T12:39:08.070113Z","iopub.status.idle":"2023-09-11T12:39:08.080015Z","shell.execute_reply.started":"2023-09-11T12:39:08.070081Z","shell.execute_reply":"2023-09-11T12:39:08.078877Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Tensor Operations\n#### Adding two tensors","metadata":{}},{"cell_type":"code","source":"x1 = torch.rand(2,3)\nx2 = torch.rand(2,3)\ny = x1+ x2 \nprint(\"sum non inplace\", y)\n\n#using inplace operations - marked with an underscore postfix\nprint(\"X2 before: \", x2)\nx2.add_(x1)\n\nprint(\"X2 after: \", x2)\n","metadata":{"execution":{"iopub.status.busy":"2023-09-11T12:39:08.081658Z","iopub.execute_input":"2023-09-11T12:39:08.082016Z","iopub.status.idle":"2023-09-11T12:39:08.094278Z","shell.execute_reply.started":"2023-09-11T12:39:08.081983Z","shell.execute_reply":"2023-09-11T12:39:08.093023Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Matmul","metadata":{}},{"cell_type":"code","source":"x = torch.arange(6).view(2,3)\nW = torch.arange(9).view(3,3)\nprint(\"X: \", x)\nprint(\"W: \", W)","metadata":{"execution":{"iopub.status.busy":"2023-09-11T12:39:08.097096Z","iopub.execute_input":"2023-09-11T12:39:08.09782Z","iopub.status.idle":"2023-09-11T12:39:08.107154Z","shell.execute_reply.started":"2023-09-11T12:39:08.097787Z","shell.execute_reply":"2023-09-11T12:39:08.106075Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"h = torch.matmul(x, W)\nprint(\"h\", h)","metadata":{"execution":{"iopub.status.busy":"2023-09-11T12:39:08.108853Z","iopub.execute_input":"2023-09-11T12:39:08.109561Z","iopub.status.idle":"2023-09-11T12:39:08.125921Z","shell.execute_reply.started":"2023-09-11T12:39:08.109527Z","shell.execute_reply":"2023-09-11T12:39:08.124924Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Tensor Reshaping","metadata":{}},{"cell_type":"code","source":"x = torch.arange(6)\nprint(\"x arange 6: \", x)\nx = x.view(2,3)\nprint(\"X reshaped 2, 3: \",x)\nx = x.view(3,2)\nprint(\"X reshaped 3, 2\", x)\n\nx = x.permute(1,0) #swapping dimension 0 and 1\nprint(\"X swappeed dimension 0 and 1(permute)\",x)","metadata":{"execution":{"iopub.status.busy":"2023-09-11T12:39:08.127399Z","iopub.execute_input":"2023-09-11T12:39:08.128088Z","iopub.status.idle":"2023-09-11T12:39:08.136449Z","shell.execute_reply.started":"2023-09-11T12:39:08.128037Z","shell.execute_reply":"2023-09-11T12:39:08.135361Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Indexing","metadata":{}},{"cell_type":"code","source":"x = torch.arange(12).view(3,4)\nx","metadata":{"execution":{"iopub.status.busy":"2023-09-11T12:39:08.140875Z","iopub.execute_input":"2023-09-11T12:39:08.141629Z","iopub.status.idle":"2023-09-11T12:39:08.148579Z","shell.execute_reply.started":"2023-09-11T12:39:08.14159Z","shell.execute_reply":"2023-09-11T12:39:08.147634Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"first column\", x[:, 0])\nprint(\"second column\", x[:, 1])\n\nprint(\"first row\", x[0])\nprint(\"secod row\", x[1])\n\nprint(\"middle two rows: \", x[1:3, :])\n","metadata":{"execution":{"iopub.status.busy":"2023-09-11T12:39:08.14991Z","iopub.execute_input":"2023-09-11T12:39:08.15058Z","iopub.status.idle":"2023-09-11T12:39:08.16102Z","shell.execute_reply.started":"2023-09-11T12:39:08.150547Z","shell.execute_reply":"2023-09-11T12:39:08.160071Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Dynamic Computation Graph and Back Propagation\n* Why do we need gradients?\n    * consider we have defined a function, a neural net, that is supposed to compute a certain output for an input vector. We then define an error measure that tells us how wrong our network is, how bad it is in predicting output y, from the input. Based on this error measure we can use the gradients to update the weights that were responsible for the output so that next time we present input to our network the output will be closer to what we want","metadata":{}},{"cell_type":"code","source":"#first thing is to specify which tensors require gradients. By default when we create a tensor it does not require gradients\nx = torch.ones((3,))\nprint(x.requires_grad)\nprint(x)","metadata":{"execution":{"iopub.status.busy":"2023-09-11T12:39:08.162224Z","iopub.execute_input":"2023-09-11T12:39:08.163305Z","iopub.status.idle":"2023-09-11T12:39:08.171405Z","shell.execute_reply.started":"2023-09-11T12:39:08.163271Z","shell.execute_reply":"2023-09-11T12:39:08.170413Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#we can change the requires grad for an existing tensor using x.requires_grad_()\nx.requires_grad_(True)\nprint(x.requires_grad)","metadata":{"execution":{"iopub.status.busy":"2023-09-11T12:39:08.172593Z","iopub.execute_input":"2023-09-11T12:39:08.173315Z","iopub.status.idle":"2023-09-11T12:39:08.181899Z","shell.execute_reply.started":"2023-09-11T12:39:08.173282Z","shell.execute_reply":"2023-09-11T12:39:08.180978Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x = torch.arange(3, dtype = torch.float32, requires_grad = True)\nprint(\"X: -> \", x)","metadata":{"execution":{"iopub.status.busy":"2023-09-11T12:39:08.183145Z","iopub.execute_input":"2023-09-11T12:39:08.183878Z","iopub.status.idle":"2023-09-11T12:39:08.192793Z","shell.execute_reply.started":"2023-09-11T12:39:08.183846Z","shell.execute_reply":"2023-09-11T12:39:08.1918Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#building the computation graph\na = x+ 2\nb = a**2\nc = b + 3\ny = c.mean()\nprint(\"Y: -> \", y)","metadata":{"execution":{"iopub.status.busy":"2023-09-11T12:39:08.194091Z","iopub.execute_input":"2023-09-11T12:39:08.194902Z","iopub.status.idle":"2023-09-11T12:39:08.210011Z","shell.execute_reply.started":"2023-09-11T12:39:08.194869Z","shell.execute_reply":"2023-09-11T12:39:08.208839Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"y -> c -> (b+3)->(b -> a -> x=2)","metadata":{}},{"cell_type":"code","source":"# # we can now perform backward propagation of the computation graph by calling the function .backward() on the last output, which effectively calculates\n# # the gradients for each tensor that has the property\ny.backward()\nprint(x.grad) #x now contains the gradient which indicates how a change in x would affect output y given the current input (0,1,2)","metadata":{"execution":{"iopub.status.busy":"2023-09-11T12:39:08.212522Z","iopub.execute_input":"2023-09-11T12:39:08.213234Z","iopub.status.idle":"2023-09-11T12:39:08.248395Z","shell.execute_reply.started":"2023-09-11T12:39:08.213208Z","shell.execute_reply":"2023-09-11T12:39:08.24744Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### GPU Support\n* A GPU can perform many thousands of small operations in parallel, making it very well suitable for performing large matrix operations in neural networks\n* Gpu availability? torch.cuda.is_available()\n* chose automatically: torch.device('cuda') if torch.cuda.is_available() else torch.device(\"cpu\")\n* by default all tensors you create are stored on the CPU. We can push a tensor to the GPU by using the function.to(cuda)","metadata":{}},{"cell_type":"code","source":"device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\ndevice","metadata":{"execution":{"iopub.status.busy":"2023-09-11T12:39:08.249546Z","iopub.execute_input":"2023-09-11T12:39:08.250411Z","iopub.status.idle":"2023-09-11T12:39:08.257526Z","shell.execute_reply.started":"2023-09-11T12:39:08.250378Z","shell.execute_reply":"2023-09-11T12:39:08.256547Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x = torch.zeros(2,3)\nx = x.to(device)\nprint(\"X\", x)","metadata":{"execution":{"iopub.status.busy":"2023-09-11T12:39:08.260296Z","iopub.execute_input":"2023-09-11T12:39:08.261014Z","iopub.status.idle":"2023-09-11T12:39:11.123729Z","shell.execute_reply.started":"2023-09-11T12:39:08.260989Z","shell.execute_reply":"2023-09-11T12:39:11.122699Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### cpu vs gpu runtime","metadata":{}},{"cell_type":"code","source":"x = torch.randn(5000, 5000)\n\n#CPU version\nstart_time = time.time()\n_ = torch.matmul(x, x)\nend_time = time.time()\n\nprint(f\"CPU time: {(end_time-start_time):6.5f}s\")\n\n#GPU version\nif torch.cuda.is_available():\n    x = x.to(device)\n    start = torch.cuda.Event(enable_timing= True)\n    end = torch.cuda.Event(enable_timing= True)\n    start.record()\n    _ = torch.matmul(x,x)\n    end.record()\n    torch.cuda.synchronize()\n    print(f\"GPU time: {0.001 * start.elapsed_time(end):6.5f}s\")  # Milliseconds to seconds","metadata":{"execution":{"iopub.status.busy":"2023-09-11T12:39:11.125274Z","iopub.execute_input":"2023-09-11T12:39:11.12583Z","iopub.status.idle":"2023-09-11T12:39:14.685774Z","shell.execute_reply.started":"2023-09-11T12:39:11.125796Z","shell.execute_reply":"2023-09-11T12:39:14.684689Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Reproducibility while using GPU","metadata":{}},{"cell_type":"code","source":"## GPU operations have separate seed we also want to set\nif torch.cuda.is_available():\n    torch.cuda.manual_seed(42)\n    torch.cuda.manual_seed_all(42)\n\n#we want to ensure that all operations are deterministic on GPU (if ussed) for reproducibility\ntorch.backends.cudnn.deterministic = True\ntorch.backends.cudnn.benchmark = False","metadata":{"execution":{"iopub.status.busy":"2023-09-11T12:39:14.686999Z","iopub.execute_input":"2023-09-11T12:39:14.687548Z","iopub.status.idle":"2023-09-11T12:39:14.693312Z","shell.execute_reply.started":"2023-09-11T12:39:14.687514Z","shell.execute_reply":"2023-09-11T12:39:14.692406Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Continuous XOR\n* torch.nn defines a series of useful classes like linear networks layers, activation functions , loss functions\n* torch.nn.functional contains functions that are used in network layers\n* nn.Module -> a nn is built up out of modules. Modules can contain other modules and a nn is considered to be a module itself as well","metadata":{}},{"cell_type":"code","source":"class SimpleClassifier(nn.Module):\n    def __init__(self, num_inputs, num_hidden, num_outputs):\n        super().__init__()\n        #some init for my module\n        self.linear1 = nn.Linear(num_inputs, num_hidden)\n        self.act_fn = nn.Tanh()\n        self.linear2 = nn.Linear(num_hidden, num_outputs)\n        \n    def forward(self, x):\n        #function for performing the calculation of the module\n        x = self.linear1(x)\n        x= self.act_fn(x)\n        x = self.linear2(x)\n        return x\n    \n#a simple nn with 2 input neurons and four hidden neurons\nmodel = SimpleClassifier(num_inputs = 2, num_hidden = 4, num_outputs =1)\nprint(model)","metadata":{"execution":{"iopub.status.busy":"2023-09-11T12:39:54.324194Z","iopub.execute_input":"2023-09-11T12:39:54.324606Z","iopub.status.idle":"2023-09-11T12:39:54.340429Z","shell.execute_reply.started":"2023-09-11T12:39:54.324574Z","shell.execute_reply":"2023-09-11T12:39:54.339096Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for name, param in model.named_parameters():\n    print(f\"Parameter {name}, shape {param.shape}\")","metadata":{"execution":{"iopub.status.busy":"2023-09-11T12:41:41.408754Z","iopub.execute_input":"2023-09-11T12:41:41.409145Z","iopub.status.idle":"2023-09-11T12:41:41.414981Z","shell.execute_reply.started":"2023-09-11T12:41:41.409114Z","shell.execute_reply":"2023-09-11T12:41:41.414075Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### The dataset class\n* torch.utils.data defines two data classes namely: data.Dataset and data.DataLoader\n* data.Dataset providees a uniform interface to access the training/test data\n    * we specify the __getitem__ to return the i-th data point in the dataset and __len__ to return the size of the dataset\n* data.DataLoader makes sure to efficiently load and stack the data points from the dataset into batches during training\n    * batch_size: No of samples to stack per batch\n    * shuffle; if true return the data in a random order\n    * num_workers: number of subprocesses to use for data loading\n    * pin memory: copies Tensors into CUDA pinned memory before returning them, can save some time for large data points on GPUs(for train)\n    * drop last: if true the last batch is dropped in case it is smaller than the specified batch size\n    \n","metadata":{}},{"cell_type":"code","source":"class XORDataset(data.Dataset):\n    def __init__(self, size, std=0.1):\n        \"\"\"\n            inputs: \n                size - NUmber of data points we need to generate\n                std - std of the noise(used in the generate_continuous_xor)\n        \"\"\"\n        super().__init__()\n        self.size = size\n        self.std = std\n        self.generate_continous_xor()\n        \n    def generate_continous_xor(self):\n        \"\"\"\n            each data point in the XOR dataset has two variables , x and y that can either be 0 or 1\n            the label is their XOR combination i.e 1 if only x or only y is 1 while the other is 0\n            if x=y , the label is 0\n        \"\"\"\n        data = torch.randint(low=0, high =2, size = (self.size, 2), dtype = torch.float32)\n        label = (data.sum(dim=1) ==1).to(torch.long)\n        # we add a bit of gaussian noise to the data points\n        data += self.std * torch.randn(data.shape) #add a bit of gaussian noise to make it challenging\n        \n        self.data = data\n        self.label  = label\n        \n    def __len__(self):\n        #number of data points we have\n        return self.size\n    \n    def __getitem__(self, idx):\n        #return the idx-ith data point of the dataset\n        data_point = self.data[idx]\n        data_label = self.label[idx]\n        return data_point, data_label\n        \n        ","metadata":{"execution":{"iopub.status.busy":"2023-09-11T12:57:11.112564Z","iopub.execute_input":"2023-09-11T12:57:11.112905Z","iopub.status.idle":"2023-09-11T12:57:11.121373Z","shell.execute_reply.started":"2023-09-11T12:57:11.112876Z","shell.execute_reply":"2023-09-11T12:57:11.120305Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset = XORDataset(size =200)\nprint(\"Size of dataset: \", len(dataset))\nprint(\"Data Point 0: \", dataset[0])","metadata":{"execution":{"iopub.status.busy":"2023-09-11T12:57:12.12715Z","iopub.execute_input":"2023-09-11T12:57:12.12749Z","iopub.status.idle":"2023-09-11T12:57:12.135351Z","shell.execute_reply.started":"2023-09-11T12:57:12.127457Z","shell.execute_reply":"2023-09-11T12:57:12.134279Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def visualize_samples(data, label):\n    if isinstance(data, Tensor):\n        data = data.cpu().numpy()\n    if isinstance(label, Tensor):\n        label = label.cpu().numpy()\n        \n    data_0 = data[label == 0]\n    data_1 = data[label == 1]\n    \n    \n    plt.figure(figsize=(4, 4))\n    plt.scatter(data_0[:, 0], data_0[:, 1], edgecolor=\"#333\", label=\"Class 0\")\n    plt.scatter(data_1[:, 0], data_1[:, 1], edgecolor=\"#333\", label=\"Class 1\")\n    plt.title(\"Dataset samples\")\n    plt.ylabel(r\"$x_2$\")\n    plt.xlabel(r\"$x_1$\")\n    plt.legend()\n    \nvisualize_samples(dataset.data, dataset.label)","metadata":{"execution":{"iopub.status.busy":"2023-09-11T13:05:47.077925Z","iopub.execute_input":"2023-09-11T13:05:47.078444Z","iopub.status.idle":"2023-09-11T13:05:48.490839Z","shell.execute_reply.started":"2023-09-11T13:05:47.078417Z","shell.execute_reply":"2023-09-11T13:05:48.489898Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### DataLoader","metadata":{}},{"cell_type":"code","source":"data_loader = data.DataLoader(dataset, batch_size =8, shuffle = True)\n\ndata_inputs , data_labels = next(iter(data_loader))\n\nprint(\"Data inputs\", data_inputs.shape, \"\\n\", data_inputs)\nprint(\"Data labels\", data_labels.shape, \"\\n\", data_labels)","metadata":{"execution":{"iopub.status.busy":"2023-09-11T13:10:52.97073Z","iopub.execute_input":"2023-09-11T13:10:52.97116Z","iopub.status.idle":"2023-09-11T13:10:52.990736Z","shell.execute_reply.started":"2023-09-11T13:10:52.971122Z","shell.execute_reply":"2023-09-11T13:10:52.989824Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Optimization\n* Get a batch from the data loader\n* Obtain the predictions from the model for the batch\n* calculate the loss based on the difference btwn predictions and labels\n* backpropagation: calculate the gradients for every parameter with respect to the loss\n* update the parameters of the model in the direction of the gradients\n\npytorch loss functions\n* nn.BCELoss()\n* nn.BCEWithLogitsLoss() - combines a sigmoid layer and the BCE loss in a single class(more stable)\n\npytorch optimizers\n* torch.optim.SGD - SGD updates params by multiplying the gradients with a small constant , called Learning rate, and subtracting those from the parameters(hence minimizing the loss) therefore we slowly move towards the direction of minimizing the loss\n    * optimizer.step() - updates the params based the gradients as explained above\n    * optimizer.zero_grad() - sets the grdients of all parameters to zero - crucial step before performing back propagation\n        * we need to clear the grads because the gradients would be added to the prev ones instead of overwriting them(a param might occur multiple times in a computation graph and we need to sum the gradients in this case instead of replacing them)\n        * call optimizer.zero_grad() before calculating the gradients of a batch\n        \n      \n\n    ","metadata":{}},{"cell_type":"code","source":"loss_module = nn.BCEWithLogitsLoss()\noptimizer = torch.optim.SGD(model.parameters(), lr=0.1)","metadata":{"execution":{"iopub.status.busy":"2023-09-11T13:37:53.911669Z","iopub.execute_input":"2023-09-11T13:37:53.912016Z","iopub.status.idle":"2023-09-11T13:37:53.917427Z","shell.execute_reply.started":"2023-09-11T13:37:53.911987Z","shell.execute_reply":"2023-09-11T13:37:53.916291Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Training\n* Push our model to the desired device\n* Set our model to training mode\n    * there exists certain modules that need to perform a different forward step during training than during testing(BatchNorm and DropOut) and we can switch btwn them using model.train() and model.eval()","metadata":{}},{"cell_type":"code","source":"train_dataset = XORDataset(size =1000)\ntrain_data_loader = data.DataLoader(train_dataset, batch_size = 128, shuffle = True)\n#push the data to the device of our choice(GPU if available)\nmodel.to(device)","metadata":{"execution":{"iopub.status.busy":"2023-09-11T13:37:54.941345Z","iopub.execute_input":"2023-09-11T13:37:54.941706Z","iopub.status.idle":"2023-09-11T13:37:54.950675Z","shell.execute_reply.started":"2023-09-11T13:37:54.941677Z","shell.execute_reply":"2023-09-11T13:37:54.949638Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train_model(model, optimizer, data_loader, loss_module, num_epochs=100):\n    model.train() #set the model in training mode\n    \n    for epoch in tqdm(range(num_epochs)):\n        for data_inputs , data_labels in data_loader:\n            #step 1; Move input data to device (only strictly necessary if we use GPU)\n            data_inputs = data_inputs.to(device)\n            data_labels = data_labels.to(device)\n            \n            #step 2: Run the model on the input data\n            preds = model(data_inputs)\n            preds = preds.squeeze(dim=1) #Output is [Batch_size, 1] but we want [Batch_size] -remove unnecessary dimensions\n            \n            #step3: calculate the loss\n            loss = loss_module(preds, data_labels.float())\n            \n            #step 4: perform backpropagation\n            #Before calculating the gradients we need to ensure they are all zero\n            #The gradients would not be overwritten , but actually added to existing ones\n            optimizer.zero_grad()\n            #perform backpropagation\n            loss.backward()\n            \n            #step5: Update the parameters\n            optimizer.step()\n\ntrain_model(model, optimizer, train_data_loader, loss_module)","metadata":{"execution":{"iopub.status.busy":"2023-09-11T13:38:05.329301Z","iopub.execute_input":"2023-09-11T13:38:05.330453Z","iopub.status.idle":"2023-09-11T13:38:06.954088Z","shell.execute_reply.started":"2023-09-11T13:38:05.330416Z","shell.execute_reply":"2023-09-11T13:38:06.953114Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Saving a model\n* we extract the so called state-dict which contains all learnable parameters","metadata":{}},{"cell_type":"code","source":"state_dict = model.state_dict()\nprint(state_dict)","metadata":{"execution":{"iopub.status.busy":"2023-09-11T13:39:19.132746Z","iopub.execute_input":"2023-09-11T13:39:19.133024Z","iopub.status.idle":"2023-09-11T13:39:19.1489Z","shell.execute_reply.started":"2023-09-11T13:39:19.132999Z","shell.execute_reply":"2023-09-11T13:39:19.147722Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#saving the state\ntorch.save(state_dict, \"our_model.tar\")","metadata":{"execution":{"iopub.status.busy":"2023-09-11T13:39:49.249959Z","iopub.execute_input":"2023-09-11T13:39:49.250989Z","iopub.status.idle":"2023-09-11T13:39:49.259541Z","shell.execute_reply.started":"2023-09-11T13:39:49.250883Z","shell.execute_reply":"2023-09-11T13:39:49.258434Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#load the state dict from the disk\nstate_dict = torch.load(\"our_model.tar\")\n\n#create a new model and load the state\nnew_model = SimpleClassifier(num_inputs = 2, num_hidden=4, num_outputs = 1)\nnew_model.load_state_dict(state_dict)\n\n#verify that the paramters are the same\n\n# Verify that the parameters are the same\nprint(\"Original model\\n\", model.state_dict())\nprint(\"\\nLoaded model\\n\", new_model.state_dict())","metadata":{"execution":{"iopub.status.busy":"2023-09-11T13:42:00.563704Z","iopub.execute_input":"2023-09-11T13:42:00.564413Z","iopub.status.idle":"2023-09-11T13:42:00.57964Z","shell.execute_reply.started":"2023-09-11T13:42:00.564368Z","shell.execute_reply":"2023-09-11T13:42:00.578504Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Evaluation\n* we dont need to keep track of the computational graph as we do not intend to calculate the gradients hence reducing the required memory and speed up the model -> with torch.no_grad() to deactivate it\n* set the model in eval mode","metadata":{}},{"cell_type":"code","source":"test_dataset = XORDataset(size = 500)\ntest_data_loader = data.DataLoader(test_dataset, batch_size=128, shuffle =False, drop_last = False)\n","metadata":{"execution":{"iopub.status.busy":"2023-09-11T13:43:50.091776Z","iopub.execute_input":"2023-09-11T13:43:50.092459Z","iopub.status.idle":"2023-09-11T13:43:50.098826Z","shell.execute_reply.started":"2023-09-11T13:43:50.09241Z","shell.execute_reply":"2023-09-11T13:43:50.097907Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def eval_model(model, data_loader):\n    model.eval()\n    true_preds, num_preds = 0.0, 0.0\n    with torch.no_grad():\n        for data_inputs, data_labels in data_loader:\n            \n            data_inputs, data_labels = data_inputs.to(device), data_labels.to(device)\n            preds = model(data_inputs)\n            preds = preds.squeeze(dim=1)\n            preds = torch.sigmoid(preds) #map predictions between 0 and 1\n            pred_labels = (preds>=0.5).long() #binarize predictions\n            \n            true_preds += (pred_labels == data_labels).sum()\n            num_preds += data_labels.shape[0]\n            \n    acc = true_preds / num_preds\n    print(f\"Accuracy of the model: {100.0*acc:4.2f}%\")","metadata":{"execution":{"iopub.status.busy":"2023-09-11T13:49:38.082371Z","iopub.execute_input":"2023-09-11T13:49:38.082715Z","iopub.status.idle":"2023-09-11T13:49:38.089882Z","shell.execute_reply.started":"2023-09-11T13:49:38.082686Z","shell.execute_reply":"2023-09-11T13:49:38.088902Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"new_model.to(device) #move the loaded model to device\neval_model(new_model, test_data_loader)","metadata":{"execution":{"iopub.status.busy":"2023-09-11T13:50:35.397526Z","iopub.execute_input":"2023-09-11T13:50:35.398402Z","iopub.status.idle":"2023-09-11T13:50:35.411784Z","shell.execute_reply.started":"2023-09-11T13:50:35.398359Z","shell.execute_reply":"2023-09-11T13:50:35.410793Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"\n### Visualizing classification boundaries\n* shows where the model has created decision boundaries and which points would be clasifed as 0 and which as 1\n    * blue-class 0\n    * orange - class 1\n    * blurry - unsure","metadata":{}},{"cell_type":"code","source":"@torch.no_grad()  # Decorator, same effect as \"with torch.no_grad(): ...\" over the whole function.\ndef visualize_classification(model, data, label):\n    if isinstance(data, Tensor):\n        data = data.cpu().numpy()\n    if isinstance(label, Tensor):\n        label = label.cpu().numpy()\n    data_0 = data[label == 0]\n    data_1 = data[label == 1]\n\n    plt.figure(figsize=(4, 4))\n    plt.scatter(data_0[:, 0], data_0[:, 1], edgecolor=\"#333\", label=\"Class 0\")\n    plt.scatter(data_1[:, 0], data_1[:, 1], edgecolor=\"#333\", label=\"Class 1\")\n    plt.title(\"Dataset samples\")\n    plt.ylabel(r\"$x_2$\")\n    plt.xlabel(r\"$x_1$\")\n    plt.legend()\n\n    # Let's make use of a lot of operations we have learned above\n    model.to(device)\n    c0 = Tensor(to_rgba(\"C0\")).to(device)\n    c1 = Tensor(to_rgba(\"C1\")).to(device)\n    x1 = torch.arange(-0.5, 1.5, step=0.01, device=device)\n    x2 = torch.arange(-0.5, 1.5, step=0.01, device=device)\n    xx1, xx2 = torch.meshgrid(x1, x2)  # Meshgrid function as in numpy\n    model_inputs = torch.stack([xx1, xx2], dim=-1)\n    preds = model(model_inputs)\n    preds = torch.sigmoid(preds)\n    # Specifying \"None\" in a dimension creates a new one\n    output_image = (1 - preds) * c0[None, None] + preds * c1[None, None]\n    output_image = (\n        output_image.cpu().numpy()\n    )  # Convert to numpy array. This only works for tensors on CPU, hence first push to CPU\n    plt.imshow(output_image, origin=\"lower\", extent=(-0.5, 1.5, -0.5, 1.5))\n    plt.grid(False)\n\n\nvisualize_classification(new_model, dataset.data, dataset.label)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-09-11T13:51:51.445759Z","iopub.execute_input":"2023-09-11T13:51:51.446318Z","iopub.status.idle":"2023-09-11T13:51:52.335923Z","shell.execute_reply.started":"2023-09-11T13:51:51.446283Z","shell.execute_reply":"2023-09-11T13:51:52.334987Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}